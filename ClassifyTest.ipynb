{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import (\n",
    "    metrics,\n",
    "    model_selection,\n",
    "    svm,\n",
    "    ensemble\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING PREPARATION - EXPLAINED IN THE OTHER NOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_accidents = pd.read_csv(\n",
    "    'data/accidents.csv',\n",
    "    header=0\n",
    ")\n",
    "dataset_accidents = dataset_accidents.drop_duplicates()\n",
    "\n",
    "dataset_vehicles = pd.read_csv(\n",
    "    'data/vehicles.csv',\n",
    "    header=0\n",
    ")\n",
    "dataset_vehicles = dataset_vehicles.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of training set (explained in the other notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_accidents = dataset_accidents[\n",
    "    dataset_accidents['latitude'] >= 40\n",
    "]\n",
    "\n",
    "dropped_cols_begin = [\n",
    "    'location_easting_osgr', 'location_northing_osgr',\n",
    "    'lsoa_of_accident_location', 'latitude', 'longitude',\n",
    "    'local_authority_district', 'local_authority_highway',\n",
    "    'pedestrian_crossing-human_control',\n",
    "    'pedestrian_crossing-physical_facilities',\n",
    "    'carriageway_hazards', '1st_road_number', '2nd_road_number'\n",
    "]\n",
    "\n",
    "dataset_accidents.drop(dropped_cols_begin, axis=1, inplace=True)\n",
    "\n",
    "dataset_accidents['weekday'] = pd.to_datetime(\n",
    "    dataset_accidents['date']\n",
    ").dt.weekday_name\n",
    "dataset_accidents['weekend'] = (dataset_accidents['weekday'].isin(\n",
    "    ['Friday', 'Saturday', 'Sunday']\n",
    "))*1\n",
    "dataset_accidents['day_period'] = pd.to_datetime(\n",
    "    dataset_accidents['time']\n",
    ").dt.hour\n",
    "dataset_accidents['day_period'] = pd.cut(\n",
    "    dataset_accidents['day_period'], bins=[0, 7, 9, 13, 16, 20, 24], right=False\n",
    ")\n",
    "dataset_accidents['urban_area'] = 1*(\n",
    "    dataset_accidents['urban_or_rural_area'] == 'Urban'\n",
    ")\n",
    "\n",
    "dropped_cols_intermediate = ['date', 'time', 'weekday', 'urban_or_rural_area']\n",
    "dataset_accidents.drop(dropped_cols_intermediate, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MERGING BOTH DATASETS USING PRIMARY KEY TO HAVE INFORMATION FROM TWO SOURCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_accidents.merge(dataset_vehicles, on='accident_id')\n",
    "\n",
    "dataset = dataset.drop('accident_id', axis=1)\n",
    "\n",
    "dataset['Towing_and_Articulation'] = (~dataset['Towing_and_Articulation'].isin(\n",
    "    ['-1', 'No tow/articulation']\n",
    "))\n",
    "dataset['Carriageway_Left'] = (dataset['Vehicle_Leaving_Carriageway'] != 'Did not leave carriageway')*1\n",
    "\n",
    "dataset['Skidding_and_Overturning'] = dataset[\n",
    "    dataset['Skidding_and_Overturning'].isin(['-1', 'None'])\n",
    "]\n",
    "\n",
    "dropped_cols_end = [\n",
    "    'Sex_of_Driver', 'Vehicle_Reference',\n",
    "    'Vehicle_IMD_Decile', 'Driver_IMD_Decile',\n",
    "    'Was_Vehicle_Left_Hand_Drive?', 'Hit_Object_in_Carriageway',\n",
    "    'Driver_Home_Area_Type', 'Vehicle_Leaving_Carriageway',\n",
    "    'Junction_Location', 'Journey_Purpose_of_Driver'\n",
    "]\n",
    "\n",
    "dataset.drop(dropped_cols_end, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISSING DATA HANDLING\n",
    "### Missing values for categorical data are replaced with the mode of the variable (common point imputation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data = {\n",
    "    'Propulsion_Code': dataset['Propulsion_Code'].mode()[0],\n",
    "    'Vehicle_Type': dataset['Vehicle_Type'].mode()[0],\n",
    "    'Vehicle_Location-Restricted_Lane': dataset[\n",
    "        'Vehicle_Location-Restricted_Lane'\n",
    "    ].mode()[0],\n",
    "    'Skidding_and_Overturning': dataset['Skidding_and_Overturning'].mode()[0],\n",
    "    'Hit_Object_off_Carriageway': dataset['Hit_Object_off_Carriageway'].mode()[0],\n",
    "}\n",
    "\n",
    "for key, val in missing_data.items():\n",
    "    dataset.loc[dataset[key] == '-1', key] = val\n",
    "\n",
    "dataset = pd.get_dummies(dataset)\n",
    "dataset = pd.get_dummies(\n",
    "    dataset,\n",
    "    columns=['road_type', 'weather_conditions']\n",
    ")\n",
    "\n",
    "dataset = dataset[dataset.columns.drop(list(dataset.filter(regex='-1')))]\n",
    "\n",
    "dataset = dataset.sample(frac=1)\n",
    "\n",
    "x = dataset.drop('target', axis=1)\n",
    "y = dataset['target']\n",
    "\n",
    "classifier = ensemble.RandomForestClassifier(\n",
    "    n_estimators=100, max_depth=20, class_weight='balanced'\n",
    ")\n",
    "\n",
    "classifier.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICTION PHASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = pd.read_csv(\n",
    "    'data/test.csv',\n",
    "    header=0\n",
    ")\n",
    "\n",
    "dataset_test.drop(dropped_cols_begin, axis=1, inplace=True)\n",
    "\n",
    "dataset_test['weekday'] = pd.to_datetime(\n",
    "    dataset_test['date']\n",
    ").dt.weekday_name\n",
    "dataset_test['weekend'] = (dataset_test['weekday'].isin(\n",
    "    ['Friday', 'Saturday', 'Sunday']\n",
    "))*1\n",
    "dataset_test['day_period'] = pd.to_datetime(\n",
    "    dataset_test['time']\n",
    ").dt.hour\n",
    "dataset_test['day_period'] = pd.cut(\n",
    "    dataset_test['day_period'], bins=[0, 7, 9, 13, 16, 20, 24], right=False\n",
    ")\n",
    "dataset_test['urban_area'] = 1*(\n",
    "    dataset_test['urban_or_rural_area'] == 'Urban'\n",
    ")\n",
    "\n",
    "dataset_test.drop(dropped_cols_intermediate, axis=1, inplace=True)\n",
    "\n",
    "dataset_test = dataset_test.merge(dataset_vehicles, on='accident_id')\n",
    "\n",
    "dataset_ids = dataset_test['accident_id']\n",
    "dataset_test = dataset_test.drop('accident_id', axis=1)\n",
    "\n",
    "dataset_test['Towing_and_Articulation'] = (~dataset_test['Towing_and_Articulation'].isin(\n",
    "    ['-1', 'No tow/articulation']\n",
    "))\n",
    "dataset_test['Carriageway_Left'] = (\n",
    "    dataset_test['Vehicle_Leaving_Carriageway'] != 'Did not leave carriageway'\n",
    ")*1\n",
    "\n",
    "dataset_test['Skidding_and_Overturning'] = dataset_test[\n",
    "    dataset_test['Skidding_and_Overturning'].isin(['-1', 'None'])\n",
    "]\n",
    "\n",
    "for key, val in missing_data.items():\n",
    "    dataset_test.loc[dataset_test[key] == '-1', key] = val\n",
    "\n",
    "dataset_test = pd.get_dummies(dataset_test)\n",
    "dataset_test = pd.get_dummies(\n",
    "    dataset_test,\n",
    "    columns=['road_type', 'weather_conditions']\n",
    ")\n",
    "\n",
    "dataset_test = dataset_test[\n",
    "    dataset_test.columns.drop(list(dataset_test.filter(regex='-1')))\n",
    "]\n",
    "\n",
    "missing_cols = set(x.columns) - set(dataset_test.columns)\n",
    "for col in missing_cols:\n",
    "    dataset_test[col] = 0\n",
    "\n",
    "dataset_test = dataset_test[x.columns]\n",
    "\n",
    "predictions = classifier.predict(dataset_test)\n",
    "\n",
    "predictions_df = pd.DataFrame(\n",
    "    {'id': dataset_ids, 'prediction': predictions}\n",
    ")\n",
    "\n",
    "final_preds = predictions_df.groupby('id').mean()\n",
    "final_preds = final_preds.astype(int).reindex(dataset_ids.unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
