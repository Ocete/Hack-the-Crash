{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import (\n",
    "    metrics,\n",
    "    model_selection,\n",
    "    svm,\n",
    "    ensemble\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read CSVs from memory and remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_accidents = pd.read_csv(\n",
    "    'data/accidents.csv',\n",
    "    header=0\n",
    ")\n",
    "dataset_accidents = dataset_accidents.drop_duplicates()\n",
    "\n",
    "dataset_vehicles = pd.read_csv(\n",
    "    'data/vehicles.csv',\n",
    "    header=0\n",
    ")\n",
    "dataset_vehicles = dataset_vehicles.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were some accidents placed in the coast of Morocco, we suppose all of them are noise and they get discarded. Moreover, they are all from the majority class, so, it's  not too problematic to load information with this drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_accidents = dataset_accidents[\n",
    "    dataset_accidents['latitude'] >= 40\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information about location is redundant with the ```police_force``` column, since the whole country is divided in regions controlled by each force."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_accidents = dataset_accidents.drop(\n",
    "    ['location_easting_osgr', 'location_northing_osgr',\n",
    "     'lsoa_of_accident_location', 'latitude', 'longitude'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables ```police_force```, ```local_authority_highway``` and ```local_authority_district``` represent the same information, so only the most concise information is kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_accidents = dataset_accidents.drop(\n",
    "    ['local_authority_district', 'local_authority_highway'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temporal information converted into more relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_accidents['weekday'] = pd.to_datetime(\n",
    "    dataset_accidents['date']\n",
    ").dt.weekday_name\n",
    "dataset_accidents['weekend'] = (dataset_accidents['weekday'].isin(\n",
    "    ['Friday', 'Saturday', 'Sunday']\n",
    "))*1\n",
    "dataset_accidents['day_period'] = pd.to_datetime(\n",
    "    dataset_accidents['time']\n",
    ").dt.hour\n",
    "dataset_accidents['day_period'] = pd.cut(\n",
    "    dataset_accidents['day_period'], bins=[0, 7, 9, 13, 16, 20, 24], right=False\n",
    ")\n",
    "dataset_accidents = dataset_accidents.drop(['date', 'time', 'weekday'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables with too much invalid or non computed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_accidents = dataset_accidents.drop(\n",
    "    [\n",
    "        'pedestrian_crossing-human_control',\n",
    "        'pedestrian_crossing-physical_facilities',\n",
    "        'carriageway_hazards'\n",
    "    ],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Urban and rural into boolean variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_accidents['urban_area'] = 1*(\n",
    "    dataset_accidents['urban_or_rural_area'] == 'Urban'\n",
    ")\n",
    "dataset_accidents = dataset_accidents.drop('urban_or_rural_area', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class is more representative than the number of the road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_accidents = dataset_accidents.drop(\n",
    "    ['1st_road_number', '2nd_road_number'], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merging** both datasets using primary key to have information from two sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_accidents.merge(dataset_vehicles, on='accident_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop ```accident_id``` since it's irrelevant after merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop('accident_id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We delete the sex of the driver on purpose since we prefer not to take this information into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop('Sex_of_Driver', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A code identifier about the car is not important to predict the severity of an accident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop('Vehicle_Reference', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentage of serious accidents is approx. constant independently of IMD value, so discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(['Vehicle_IMD_Decile', 'Driver_IMD_Decile'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left or right hand drive is not useful since almost every value is no and the proportion of serious accidents is almost constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(['Was_Vehicle_Left_Hand_Drive?'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost every vehicle is not articulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Towing_and_Articulation'] = (~dataset['Towing_and_Articulation'].isin(\n",
    "    ['-1', 'No tow/articulation']\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting this variable because almost every value is none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop('Hit_Object_in_Carriageway', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't know the meaning of this variable and we cannot obtain it, we decide to drop this variable since it's not very informative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(\n",
    "    'Driver_Home_Area_Type',\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This variable gets converted into 0-1 encoding whether the vehicle has abandoned the carriageway or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Carriageway_Left'] = (dataset['Vehicle_Leaving_Carriageway'] != 'Did not leave carriageway')*1\n",
    "\n",
    "dataset = dataset.drop('Vehicle_Leaving_Carriageway', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting it since it is not very informative variable for the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop('Journey_Purpose_of_Driver', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Junction_Location collides with another column from accidents. Deleting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop('Junction_Location', axis=1)\n",
    "\n",
    "dataset['Skidding_and_Overturning'] = dataset[\n",
    "    dataset['Skidding_and_Overturning'].isin(['-1', 'None'])\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISSING DATA HANDLING\n",
    "Missing values for categorical data are replaced with the mode of the variable (common point imputation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[dataset['Vehicle_Type'] == '-1', 'Vehicle_Type'] = dataset['Vehicle_Type'].mode()\n",
    "\n",
    "dataset.loc[\n",
    "    dataset['Vehicle_Location-Restricted_Lane'] == '-1', 'Vehicle_Location-Restricted_Lane'\n",
    "] = dataset['Vehicle_Location-Restricted_Lane'].mode()\n",
    "\n",
    "dataset.loc[\n",
    "    dataset['Hit_Object_off_Carriageway'] == '-1', 'Hit_Object_off_Carriageway'\n",
    "] = dataset['Hit_Object_off_Carriageway'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset permutation and obtention of remaining onehot variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.sample(frac=1, random_state=42)\n",
    "dataset = pd.get_dummies(dataset)\n",
    "dataset = pd.get_dummies(\n",
    "    dataset,\n",
    "    columns=['road_type', 'weather_conditions']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deletion of columns relative to -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset.columns.drop(list(dataset.filter(regex='-1')))]\n",
    "\n",
    "x = dataset.drop('target', axis=1)\n",
    "y = dataset['target']\n",
    "\n",
    "skf = model_selection.StratifiedKFold(n_splits=5)\n",
    "\n",
    "classifier = ensemble.RandomForestClassifier(\n",
    "    n_estimators=200, max_depth=50, class_weight='balanced'\n",
    ")\n",
    "\n",
    "split_indices = skf.split(x, y)\n",
    "scores = []\n",
    "f1_scores = []\n",
    "confusion_matrices = []\n",
    "\n",
    "for train_index, test_index in split_indices:\n",
    "    print(\"New split\")\n",
    "    print(\"Train size: {}, test size: {}\".format(\n",
    "        len(train_index), len(test_index)\n",
    "    ))\n",
    "\n",
    "    train_set, train_labels = x.loc[train_index], y[train_index]\n",
    "    test_set, test_labels = x.loc[test_index], y[test_index]\n",
    "    train_set, train_labels = rus.fit_resample(train_set, train_labels)\n",
    "    classifier.fit(train_set, train_labels)\n",
    "\n",
    "    labels_pred = classifier.predict(test_set)\n",
    "\n",
    "    curr_score = metrics.accuracy_score(test_labels, labels_pred)\n",
    "    curr_f1 = metrics.f1_score(test_labels, labels_pred, average='binary')\n",
    "    conf_matrix = metrics.confusion_matrix(test_labels, labels_pred)\n",
    "    print(\"Acc: {}, F1: {}\".format(curr_score, curr_f1))\n",
    "    print(\"Confusion matrix\")\n",
    "    print(conf_matrix)\n",
    "    scores.append(curr_score)\n",
    "    f1_scores.append(curr_f1)\n",
    "\n",
    "print(\"Medias\")\n",
    "print(\"Acc: {}, F1: {}\".format(np.mean(scores), np.mean(f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
